{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import *\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import re,sys,pickle,math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10326</td>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10327</td>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10328</td>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10329</td>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10330</td>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id10326  The room was kind of clean but had a VERY stro...   \n",
       "1  id10327  I stayed at the Crown Plaza April -- - April -...   \n",
       "2  id10328  I booked this hotel through Hotwire at the low...   \n",
       "3  id10329  Stayed here with husband and sons on the way t...   \n",
       "4  id10330  My girlfriends and I stayed here to celebrate ...   \n",
       "\n",
       "        Browser_Used Device_Used Is_Response  \n",
       "0               Edge      Mobile   not happy  \n",
       "1  Internet Explorer      Mobile   not happy  \n",
       "2            Mozilla      Tablet   not happy  \n",
       "3   InternetExplorer     Desktop       happy  \n",
       "4               Edge      Tablet   not happy  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_train = \"train.csv\"\n",
    "train = pd.read_csv(path_train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_net(word):\n",
    "    \"\"\"\n",
    "    Aims at lemmatizing a word using synonyms of a word. \n",
    "    Longest prefix match of a word with some constraints is the lemmatized word.\n",
    "    Synonyms of a word are extracted using synsets()\n",
    "    \"\"\"\n",
    "    if(len(word)<=5):\n",
    "        return word\n",
    "    synonyms = []\n",
    "    #antonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name())\n",
    "            #if l.antonyms():\n",
    "                #antonyms.append(l.antonyms()[0].name())\n",
    "    best_match = \"\"\n",
    "    match = 0\n",
    "    if len(synonyms)==0:\n",
    "        return word\n",
    "    left_count = len(word)\n",
    "    for syn in synonyms:\n",
    "        if syn==word:\n",
    "            continue\n",
    "        temp = 0\n",
    "        flag=1\n",
    "        index = 0\n",
    "        for i in range(min(len(syn),len(word))):\n",
    "            index = i\n",
    "            if(syn[i]!=word[i]):\n",
    "                if((len(syn)-temp)<left_count):\n",
    "                    left_count = len(syn)-temp\n",
    "                    best_match = syn \n",
    "                    match = i\n",
    "                flag=0\n",
    "                break\n",
    "            temp+=1\n",
    "        if(flag==1):\n",
    "            if((len(syn)-temp)<left_count):\n",
    "                left_count = len(syn)-temp\n",
    "                best_match = syn\n",
    "                match = index+1\n",
    "    if(len(word)-match>4 or len(best_match)>=len(word) or len(best_match)<=1):\n",
    "        return word\n",
    "    return best_match\n",
    "\n",
    "def write_pkl(file,data):\n",
    "    \"\"\"\n",
    "    Writes data from a pickle file. ie. \"data.pkl\"\n",
    "    \"\"\"\n",
    "    writing = open(file, 'wb')\n",
    "    pickle.dump(data, writing)\n",
    "    return\n",
    "\n",
    "def load_pkl(file):\n",
    "    \"\"\"\n",
    "    Loads data from a pickle file. ie. \"data.pkl\"\n",
    "    \"\"\"\n",
    "    pkl_file = open(file, 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    return data\n",
    "\n",
    "corpus_size = 38932\n",
    "\n",
    "def tf(word,doc_id):\n",
    "    \"\"\"\n",
    "    Calculates and returns the term frequency log(tf+1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return math.log(multimap_list[word][doc_id][1]+1)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def idf(word):\n",
    "    \"\"\"\n",
    "    Calculaltes and returns the inverse document frequency log(N/df)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return math.log(float(corpus_size)/len(multimap_list[word]))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I stayed at the Crown Plaza April -- - April --, ----. The staff was friendly and attentive. The elevators are tiny (about -' by -'). The food in the restaurant was delicious but priced a little on the high side. Of course this is Washington DC. There is no pool and little for children to do. My room on the fifth floor had two comfortable beds and plenty of space for one person. The TV is a little small by todays standards with a limited number of channels. There was a small bit of mold in the bathtub area that could have been removed with a little bleach. It appeared the carpets were not vacummed every day. I reported a light bulb was burned out. It was never replaced. Ice machines are on the odd numbered floors, but the one on my floor did not work. I encountered some staff in the elevator one evening and I mentioned the ice machine to them. Severel hours later a maid appeared at my door with ice and two mints. I'm not sure how they knew what room I was in. That was a little unnerving! I would stay here again for business, but would not come here on vacation. (38932,)\n"
     ]
    }
   ],
   "source": [
    "desc = np.array(train[\"Description\"])\n",
    "print(desc[1],desc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: This was carried out and stored in data.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#cleaning the data \n",
    "#removing punctuations\n",
    "#to lowercase\n",
    "#remove stop words from file\n",
    "\n",
    "clean_train = []\n",
    "with open(\"stp.txt\") as file:\n",
    "    stops = file.read().splitlines()\n",
    "stops = set(stops)\n",
    "for review in desc:\n",
    "    review = re.sub(r'[^A-Za-z0-9\\s]',r'',review)\n",
    "    review = re.sub(r'\\n',r' ',review)\n",
    "    review = \" \".join([w.lower() for w in review.split()])\n",
    "    #review = \" \".join([word_net(w) for w in review.split()])\n",
    "    review = \" \".join([word_net(w) for w in review.split() if w not in stops])\n",
    "    clean_train.append(review)\n",
    "    \n",
    "write_pkl(\"data.pkl\",clean_train)\n",
    "\"\"\"\n",
    "print(\"NOTE: This was carried out and stored in data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stay crown plaza april april staff was friendly attentive elevator are tiny food restaurant was delicious but price little on high side of course is washington dc is no pool little child to do room on fifth floor had two comfortable beds plenty of space one person tv is little small today standard limit number of channel was small bit of mold bath area could have been remove little bleach appear carpet were not vacummed every day report light bulb was burn was never replace ice machine are on odd number floor but one on floor did not work encounter staff elevator one eve mention ice machine to severel hours later maid appear door ice two mints im not sure knew room was was little unnerve would stay again business but would not come on vacation\n",
      "38932\n"
     ]
    }
   ],
   "source": [
    "#Loading the cleaned training data\n",
    "clean_train = load_pkl(\"data.pkl\")\n",
    "print(clean_train[1])\n",
    "print(len(clean_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 1 0 1 1 0] 38932\n",
      "0    not happy\n",
      "1    not happy\n",
      "2    not happy\n",
      "3        happy\n",
      "4    not happy\n",
      "5        happy\n",
      "6    not happy\n",
      "7        happy\n",
      "8        happy\n",
      "9    not happy\n",
      "Name: Is_Response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#loading the result happy or not into array\n",
    "train_result = np.array(np.where((train[\"Is_Response\"]==\"not happy\"), 0, 1))\n",
    "#train_result = np.array(train[\"Is_Response\"])\n",
    "print(train_result[:10],len(train_result))\n",
    "print(train[\"Is_Response\"].head(10))\n",
    "#write_pkl(\"train_result.pkl\",train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needs Work!!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# eng_dict contains all words in dictionary\n",
    "with open(\"20k.txt\") as file:\n",
    "    eng_dict = set(file.read().split())\n",
    "\n",
    "# cleaning combined words and misspellings\n",
    "def corrected(word):\n",
    "    for i in range(len(word)):\n",
    "        if word[:i+1] in eng_dict and word[i+1:] in eng_dict:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "count = 0\n",
    "words = set([])\n",
    "for review in clean_train:\n",
    "    if(count%1000==0):\n",
    "        print(\"Review no\",count+1)\n",
    "    count+=1\n",
    "    for word in review.split():\n",
    "        if word not in eng_dict:\n",
    "            index = corrected(word)\n",
    "            if index!= -1:\n",
    "                print(word[:index+1]+\"-\"+word[index+1:],end=\" \")\n",
    "                words.add(word[:index+1])\n",
    "                words.add(word[index+1:])\n",
    "            else:\n",
    "                words.add(word)\n",
    "print(list(words)[:50],len(words))\n",
    "\"\"\"\n",
    "print(\"Needs Work!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done indexing! Load it from multimap.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#indexing\n",
    "multimap_list = {}\n",
    "doc_id = 0\n",
    "for review in clean_train:\n",
    "    doc_id+=1\n",
    "    pos = 0\n",
    "    for word in review.split():\n",
    "        pos+=1\n",
    "        try:\n",
    "            multimap_list[word][doc_id][0].append(pos)\n",
    "            multimap_list[word][doc_id][1]+=1\n",
    "        except:\n",
    "            try:\n",
    "                multimap_list[word][doc_id]=[[],[]]\n",
    "                multimap_list[word][doc_id][0]=[]\n",
    "                multimap_list[word][doc_id][1]=0\n",
    "                multimap_list[word][doc_id][0].append(pos)\n",
    "                multimap_list[word][doc_id][1]+=1\n",
    "            except:\n",
    "                multimap_list[word]={}\n",
    "                multimap_list[word][doc_id]=[[],[]]\n",
    "                multimap_list[word][doc_id][0]=[]\n",
    "                multimap_list[word][doc_id][1]=0\n",
    "                multimap_list[word][doc_id][0].append(pos)\n",
    "                multimap_list[word][doc_id][1]+=1\n",
    "    if(doc_id%1000==0):\n",
    "        print(\"length so far\",len(multimap_list))\n",
    "        \n",
    "writing = open('multimap.pkl', 'wb')\n",
    "pickle.dump(multimap_list, writing)\n",
    "\"\"\"\n",
    "print(\"Done indexing! Load it from multimap.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{30051: [[16], 1], 14951: [[152], 1], 35370: [[84], 1], 7409: [[176], 1], 30892: [[488], 1], 32305: [[45], 1], 24405: [[18], 1], 33847: [[51], 1], 13273: [[34], 1], 26939: [[24], 1], 27761: [[95], 1], 20287: [[65], 1]}\n"
     ]
    }
   ],
   "source": [
    "#Loading the indexed multimap.pkl file\n",
    "multimap_list = load_pkl(\"multimap.pkl\")\n",
    "print(multimap_list[\"drone\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couple felt comfortable return to hotel than once whenever need super affordable place to stay downtown sf age of hotel consider skyhigh price of most hotel area regardless of age was gem havent seen place since but stay least week once completely satisfy lived sf area time knew was very reasonable choice is locate on post street is literally few block everything downtown sf has to offer short walk to famed cable cars right on top of bart station come sfo airport union square great place to eat loads of public transportation hotel is also situate bottom of nob hill is very little inclination to street no steep hills to worry most cases stay decent part of downtown nob hill will require hike up crazy steep hill to access place not case dakota very easy to access convenient little market surround neighborhood last min needs also atm late night snack few block dakota sits is not most spark clean area of downtown however is securely locate few street up most sketchy part tenderloin actually lived few block dakota always felt safe possible one of busy downtown america most of sf outside milliondollar hoods is older little dirty but most of is safe stay on post street dakota just remember to stay away south of geary street unless stick to main strip mart st keep map open always block san francisco are short than usual is given almost anywhere city can literally turn block one way luxury block direction ghetto cant let scare though most of sf is like dakota is prime location within best proximity to everything even make wrong turn are always people everywhere sf usually hours can just easy make quick turn back no problem back to hotel would definitely recommend place to stay someone on budget but not want to settle shack worst part of town no worry choose place read several of review hotel travel lot know depend on are come are used to stay royal palace daily pamper place might seem like dump to however average person is clean charm safe affordable place to stay btw is usually no park hard to find street spots meter best solution is to not drive town but catch bart train airport are travel of town get around sf foot bustrain is breeze no car need unless want to go of town room was clean bed was comfortable is usally cool little view of downtown landscape window unique little surprise were birdcage elevator old fashion claw foot bath tub hallway rooms are little narrow carpet are little older but honestly most building enter san francisco are small antique will have older carpet walls etc is long post but dakota is little gem among place alike area never had bed bugs problem stay cant remember problem of significant street noise however stay anywhere downtown will put around tons of firetrucks blare siren round clock unless youre rich enough to afford one of shin mod giant hotel dowtown royal historic landmark up hill is good gets stay within budget aging yet charm city of san francisco\n"
     ]
    }
   ],
   "source": [
    "print(clean_train[21540-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran and calculated tfidf!\n"
     ]
    }
   ],
   "source": [
    "#precalc tfidf for all words for all docs\n",
    "corpus_size = 38932\n",
    "\n",
    "def tf(word,doc_id):\n",
    "    \"\"\"\n",
    "    Calculates and returns the term frequency log(tf+1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return math.log(multimap_list[word][doc_id][1]+1)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def idf(word):\n",
    "    \"\"\"\n",
    "    Calculaltes and returns the inverse document frequency log(N/df)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return math.log(float(corpus_size)/len(multimap_list[word]))\n",
    "    except:\n",
    "        return 0\n",
    "\"\"\"\n",
    "tfidf = load_pkl(\"multimap.pkl\")\n",
    "words = []\n",
    "for i in multimap_list:\n",
    "    words.append(i)\n",
    "\n",
    "for word in words[:]:\n",
    "    for doc_id in multimap_list[word]:\n",
    "        tfidf[word][doc_id][1] = tf(word,doc_id)*idf(word)\n",
    "    \n",
    "write_pkl(\"tfidf.pkl\",tfidf)\n",
    "\"\"\"\n",
    "print(\"Ran and calculated tfidf!\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
